# Histogram of the residuals
hist(rstudent(model), xlab='Jackknife Residual', main='Histogram of Residuals', freq=F, breaks=seq(-4,4,0.25))
curve(dnorm(x, mean=0, sd=1), lwd=2, col='blue', add=T)
# Normal Probability Plot
plot(ppoints(length(rstudent(model))), sort(rstudent(model)),
xlab='Theoretical Quantiles',
ylab='Studentized Residuals',
main='Normal Probability Plot', cex=0.7)
abline(a=0, b=1, col='gray65', lwd=1)
# Reset graphics layout
par(mfrow=c(1,1))
#2b
# Set the graphics layout to a 2x2 grid
par(mfrow=c(2,2), mar=c(4.1, 4.1, 3.1, 2.1))
# Scatterplot of the observed data
plot(amniotic$temp, amniotic$ln_cells, xlab='Temperature', ylab='Log of Cell Count', main='Scatterplot', cex=0.7)
abline(model, col='blue')
# Residual plot
plot(amniotic$temp, rstudent(model), xlab='Temperature', ylab='Jackknife Residual', main='Residual Plot', cex=0.7)
abline(h=0, lty=2, col='gray65')
# Histogram of the residuals
hist(rstudent(model), xlab='Jackknife Residual', main='Histogram of Residuals', freq=F)
curve(dnorm(x, mean=0, sd=1), lwd=2, col='blue', add=T)
# Normal Probability Plot
plot(ppoints(length(rstudent(model))), sort(rstudent(model)),
xlab='Theoretical Quantiles',
ylab='Studentized Residuals',
main='Normal Probability Plot', cex=0.7)
abline(a=0, b=1, col='gray65', lwd=1)
# Reset graphics layout
par(mfrow=c(1,1))
# Histogram of the residuals
hist(rstudent(model), xlab='Jackknife Residual', main='Histogram of Residuals', freq=F, breaks=seq(-40,40,0.25))
curve(dnorm(x, mean=0, sd=1), lwd=2, col='blue', add=T)
# Histogram of the residuals
hist(rstudent(model), xlab='Jackknife Residual', main='Histogram of Residuals', freq=F, breaks=seq(-10,10,0.25))
curve(dnorm(x, mean=0, sd=1), lwd=2, col='blue', add=T)
# Histogram of the residuals
hist(rstudent(model), xlab='Jackknife Residual', main='Histogram of Residuals', freq=F, breaks=seq(-4,4,0.25))
curve(dnorm(x, mean=0, sd=1), lwd=2, col='blue', add=T)
#2b
# Set the graphics layout to a 2x2 grid
par(mfrow=c(2,2), mar=c(4.1, 4.1, 3.1, 2.1))
# Scatterplot of the observed data
plot(amniotic$temp, amniotic$ln_cells, xlab='Temperature', ylab='Log of Cell Count', main='Scatterplot', cex=0.7)
abline(model, col='blue')
# Residual plot
plot(amniotic$temp, rstudent(model), xlab='Temperature', ylab='Jackknife Residual', main='Residual Plot', cex=0.7)
abline(h=0, lty=2, col='gray65')
# Histogram of the residuals
hist(rstudent(model), xlab='Jackknife Residual', main='Histogram of Residuals', freq=F, breaks=seq(-4,4,0.25))
curve(dnorm(x, mean=0, sd=1), lwd=2, col='blue', add=T)
# Normal Probability Plot
plot(ppoints(length(rstudent(model))), sort(rstudent(model)),
xlab='Theoretical Quantiles',
ylab='Studentized Residuals',
main='Normal Probability Plot', cex=0.7)
abline(a=0, b=1, col='gray65', lwd=1)
#2b
# Set the graphics layout to a 2x2 grid
par(mfrow=c(2,2), mar=c(4.1, 4.1, 3.1, 2.1))
# Scatterplot of the observed data
plot(amniotic$temp, amniotic$ln_cells, xlab='Temperature', ylab='Log of Cell Count', main='Scatterplot', cex=0.7)
abline(model, col='blue')
# Residual plot
plot(amniotic$temp, rstudent(model), xlab='Temperature', ylab='Jackknife Residual', main='Residual Plot', cex=0.7)
abline(h=0, lty=2, col='gray65')
# Histogram of the residuals
hist(rstudent(model), xlab='Jackknife Residual', main='Histogram of Residuals', freq=F, breaks=seq(-4,4,0.25))
curve(dnorm(x, mean=0, sd=1), lwd=2, col='blue', add=T)
# Normal Probability Plot
plot(ppoints(length(rstudent(model))), sort(rstudent(model)),
xlab='Observed Cumulative Probability',
ylab='Expected Cumulative Probabilityâ€™,
main='Normal Probability Plot', cex=0.7)
#2b
# Set the graphics layout to a 2x2 grid
par(mfrow=c(2,2), mar=c(4.1, 4.1, 3.1, 2.1))
# Scatterplot of the observed data
plot(amniotic$temp, amniotic$ln_cells, xlab='Temperature', ylab='Log of Cell Count', main='Scatterplot', cex=0.7)
abline(model, col='blue')
# Residual plot
plot(amniotic$temp, rstudent(model), xlab='Temperature', ylab='Jackknife Residual', main='Residual Plot', cex=0.7)
abline(h=0, lty=2, col='gray65')
# Histogram of the residuals
hist(rstudent(model), xlab='Jackknife Residual', main='Histogram of Residuals', freq=F, breaks=seq(-4,10,0.25))
curve(dnorm(x, mean=0, sd=1), lwd=2, col='blue', add=T)
# Normal Probability Plot
plot(ppoints(length(rstudent(model))), sort(rstudent(model)),
xlab='Observed Cumulative Probability',
ylab='Expected Cumulative Probability',
main='Normal Probability Plot', cex=0.7)
abline(a=0, b=1, col='gray65', lwd=1)
# Reset graphics layout
par(mfrow=c(1,1))
# Scatterplot of the observed data
plot(x = amniotic$temp, y = amniotic$ln_cells, xlab='Temperature', ylab='Log of Cell Count', main='Scatterplot', cex=0.7)
abline(model, col='blue')
#2b
# Set the graphics layout to a 2x2 grid
par(mfrow=c(2,2), mar=c(4.1, 4.1, 3.1, 2.1))
# Scatterplot of the observed data
plot(amniotic$temp, amniotic$ln_cells, xlab='Temperature', ylab='Log of Cell Count', main='Scatterplot', cex=0.7)
abline(model, col='blue')
# Residual plot
plot(amniotic$temp, rstudent(model), xlab='Temperature', ylab='Jackknife Residual', main='Residual Plot', cex=0.7)
abline(h=0, lty=2, col='gray65')
# Histogram of the residuals
hist(rstudent(model), xlab='Jackknife Residual', main='Histogram of Residuals', freq=F, breaks=seq(-4,10,0.25))
curve(dnorm(x, mean=0, sd=1), lwd=2, col='blue', add=T)
# Normal Probability Plot
plot(ppoints(length(rstudent(model))), sort(rstudent(model)),
xlab='Observed Cumulative Probability',
ylab='Expected Cumulative Probability',
main='Normal Probability Plot', cex=0.7)
abline(a=0, b=1, col='gray65', lwd=1)
# Reset graphics layout
par(mfrow=c(1,1))
amniotic <- data.frame(
cells = c(1.13,1.20,1.00,0.91,1.05,1.75,1.45,1.55,1.64,1.60,
2.30,2.15,2.25,2.40,2.49,3.18,3.10,3.28,3.35,3.12),
temp = c(rep(40,5), rep(60,5), rep(80,5), rep(100,5)))
amniotic$ln_cells <- log(amniotic$cells) # calculate log(cells)
#2a
# Perform the linear regression
model <- lm(ln_cells ~ temp, data = amniotic)
# Summary of the model to obtain coefficients
model_summary <- summary(model)
print(model_summary)
# Predicted regression equation for the outcome on the log scale
intercept <- coef(model)["(Intercept)"]
slope <- coef(model)["temp"]
#cat("Predicted regression equation (log scale): ln(cells) =", intercept, "+", slope, "* temp\n")
# Interpretation of the coefficients
#cat("Intercept interpretation: At 0 degrees temperature, the natural log of the cell count is", intercept, "\n")
#cat("Slope interpretation: For each additional degree of temperature, the natural log of the cell count increases by", slope, "\n")
# Transform the estimate of the slope and its 95% confidence interval to the original (not logged) scale
conf_int <- confint(model, level = 0.95)
slope_antilog <- exp(slope)
lower <- exp(conf_int[2,1])
upper <- exp(conf_int[2,2])
# Print
cat("Original scale slope:",slope_antilog, "\n")
cat("Original scale 95% CI:",lower, "to", upper, "\n")
# Interpretation of the transformed coefficients
cat("Transformed slope estimate: For each additional degree of temperature, the cell count is multiplied by", slope_antilog, "\n")
cat("95% confidence interval of the transformed slope:", lower, "to", upper, "\n")
# Suppose these are your p-values
p_values <- c(0.040, 0.100, 0.400, 0.550, 0.340, 0.620, 0.001, 0.010, 0.800, 0.005)
# Apply the FDR correction
p_adjusted <- p.adjust(p_values, method = "fdr")
# Print the adjusted p-values
print(p_adjusted)
# Determine which p-values are significant after FDR adjustment
significant <- p_adjusted < 0.05
# Count the number of significant p-values
num_significant <- sum(significant)
# Print the number of significant SNPs after correction
print(num_significant)
p_values <- c(0.040, 0.100, 0.400, 0.550, 0.340, 0.620, 0.001, 0.010, 0.800, 0.005)
round(cbind('fdr' = p.adjust(p_values, method = 'fdr'),
'bon' = p.adjust(p_values, method = 'bonferroni')))
p_values <- c(0.040, 0.100, 0.400, 0.550, 0.340, 0.620, 0.001, 0.010, 0.800, 0.005)
round(cbind('fdr' = p.adjust(p_values, method = 'fdr'),
'bon' = p.adjust(p_values, method = 'bonferroni')), 4)
adjusted_p_values <- round(cbind('fdr' = p.adjust(p_values, method = 'fdr'),
'bon' = p.adjust(p_values, method = 'bonferroni')), 4)
adjusted_p_values
p_values <- c(0.040, 0.100, 0.400, 0.550, 0.340, 0.620, 0.001, 0.010, 0.800, 0.005)
adjusted_p_values <- round(cbind('fdr' = p.adjust(p_values, method = 'fdr'),
'bon' = p.adjust(p_values, method = 'bonferroni')), 4)
# Determine the number of significant p-values after FDR adjustment
significant_fdr <- sum(adjusted_p_values$fdr < 0.05)
# Given p-values
p_values <- c(0.040, 0.100, 0.400, 0.550, 0.340, 0.620, 0.001, 0.010, 0.800, 0.005)
# Apply FDR and Bonferroni corrections and round the results
adjusted_p_values <- round(cbind('fdr' = p.adjust(p_values, method = 'fdr'),
'bon' = p.adjust(p_values, method = 'bonferroni')), 4)
# Convert the matrix to a dataframe
adjusted_p_values_df <- as.data.frame(adjusted_p_values)
# Determine the number of significant p-values after FDR adjustment
significant_fdr <- sum(adjusted_p_values_df$fdr < 0.05)
# Determine the number of significant p-values after Bonferroni adjustment
significant_bon <- sum(adjusted_p_values_df$bon < 0.05)
# Output the counts
print(paste("Significant SNPs after FDR correction:", significant_fdr))
print(paste("Significant SNPs after Bonferroni correction:", significant_bon))
adjusted_p_values_df
# Given p-values
p_values <- c(0.040, 0.100, 0.400, 0.550, 0.340, 0.620, 0.001, 0.010, 0.800, 0.005)
# Apply FDR and Bonferroni corrections and round the results
adjusted_p_values <- round(cbind('fdr' = p.adjust(p_values, method = 'fdr'),
'bon' = p.adjust(p_values, method = 'bonferroni')), 4)
# Convert the matrix to a dataframe
adjusted_p_values_df <- as.data.frame(adjusted_p_values)
# Determine the number of significant p-values after FDR adjustment
significant_fdr <- sum(adjusted_p_values_df$fdr < 0.05)
# Determine the number of significant p-values after Bonferroni adjustment
significant_bon <- sum(adjusted_p_values_df$bon < 0.05)
# Output the counts
print(paste("Significant SNPs after FDR correction:", significant_fdr))
print(paste("Significant SNPs after Bonferroni correction:", significant_bon))
# Given p-values
p_values <- c(0.040, 0.100, 0.400, 0.550, 0.340, 0.620, 0.001, 0.010, 0.800, 0.005)
# Apply FDR and Bonferroni corrections and round the results
adjusted_p_values <- round(cbind('fdr' = p.adjust(p_values, method = 'fdr'),
'bon' = p.adjust(p_values, method = 'bonferroni')), 4)
# Print adjusted_p_values
adjusted_p_values
# Convert the matrix to a dataframe
adjusted_p_values_df <- as.data.frame(adjusted_p_values)
# Determine the number of significant p-values after FDR adjustment
significant_fdr <- sum(adjusted_p_values_df$fdr < 0.05)
# Determine the number of significant p-values after Bonferroni adjustment
significant_bon <- sum(adjusted_p_values_df$bon < 0.05)
# Output the counts
print(paste("Significant SNPs after FDR correction:", significant_fdr))
print(paste("Significant SNPs after Bonferroni correction:", significant_bon))
# Given p-values
p_values <- c(0.040, 0.100, 0.400, 0.550, 0.340, 0.620, 0.001, 0.010, 0.800, 0.005)
# Apply FDR and Bonferroni corrections and round the results
adjusted_p_values <- round(cbind('fdr' = p.adjust(p_values, method = 'fdr'),
'bon' = p.adjust(p_values, method = 'bonferroni')), 4)
# Print adjusted_p_values
adjusted_p_values
# Convert the matrix to a dataframe
adjusted_p_values_df <- as.data.frame(adjusted_p_values)
# Determine the number of significant p-values after FDR adjustment
significant_fdr <- sum(adjusted_p_values_df$fdr < 0.05)
# Determine the number of significant p-values after Bonferroni adjustment
significant_bon <- sum(adjusted_p_values_df$bon < 0.05)
# Output the counts
print(paste("Significant SNPs after FDR correction:", significant_fdr))
print(paste("Significant SNPs after Bonferroni correction:", significant_bon))
#2a
# Create data set from table
lung <- data.frame( group=c( rep('A',5), rep('B',12), rep('C',5) ),
react=c(20.8,4.1,30,24.7,13.8,
7.5,7.5,11.9,4.5,3.1,8,4.7,28.1,10.3,10,5.1,2.2,
9.2,2,2.5,6.1,7.5) )
# Perform ANOVA
anova_result <- aov(react ~ group, data=lung)
# Display the summary of the ANOVA
summary(anova_result)
#2b
# Conduct the Tukey HSD test
tukey_result <- TukeyHSD(anova_result)
# Print the results of the Tukey HSD test
print(tukey_result)
#2b
# Conduct the Tukey HSD test
tukey_result <- TukeyHSD(anova_result)
# Print the results of the Tukey HSD test
print(tukey_result)
summary(tukey_result)
#2b
# Conduct the Tukey HSD test
tukey_result <- TukeyHSD(anova_result)
# Print the results of the Tukey HSD test
print(tukey_result)
# Perform the Kruskal-Wallis test
kruskal_result <- kruskal.test(react ~ group, data=lung)
# Print the results of the Kruskal-Wallis test
print(kruskal_result)
#2c
# Perform the Kruskal-Wallis test
kruskal_result <- kruskal.test(react ~ group, data=lung)
# Print the results of the Kruskal-Wallis test
print(kruskal_result)
# Coefficient for sex
estimate_sex <- 0.03973
standard_error_sex <- 0.44109
critical_value <- 1.96  # for 95% CI
# Calculate the lower and upper bounds of the CI
lower_bound <- estimate_sex - (critical_value * standard_error_sex)
upper_bound <- estimate_sex + (critical_value * standard_error_sex)
# Print the confidence interval
cat("The 95% CI for the coefficient associated with sex is (", lower_bound, ",", upper_bound, ")\n")
#1e
# Given values for the sum of squares and degrees of freedom
sum_squares_full_model = 81842.94
sum_squares_reduced_model = 6824.94
df_full_model = 6
df_reduced_model = 4
mean_square_error = 216.65
# Calculate the partial F-test statistic
f_statistic = ((sum_squares_full_model - sum_squares_reduced_model) / (df_full_model - df_reduced_model)) / mean_square_error
# Print the F-test statistic
cat("The partial F-test statistic is:", f_statistic, "\n")
#2a
# Coefficients for depression (crude and adjusted)
beta_crude <- -0.3779
beta_adj <- -0.02835
# Calculate percent change for biostatisticians
percent_change_biostatisticians <- ((beta_crude - beta_adj) / beta_crude) * 100
# Calculate percent change for epidemiologists
percent_change_epidemiologists <- ((beta_crude - beta_adj) / beta_adj) * 100
# Print the results
cat("Percent change for biostatisticians:", percent_change_biostatisticians, "%\n")
cat("Percent change for epidemiologists:", percent_change_epidemiologists, "%\n")
#4c
p1 <- 1009/1660
p2 <- 1526/3117
a <- p1/p2
a
a5 <- effect_size/sd*sqrt(size) - 1.96
effect_size <- 1/1.5
sd <- 1.5
size <- 30
a5 <- effect_size/sd*sqrt(size) - 1.96
a5
effect_size <- 1
sd <- 1.5
size <- 30
a5 <- effect_size/sd*sqrt(size) - 1.96
a5
effect_size <- 1
sd <- 1.5
size <- 30
a5 <- effect_size/sd/sqrt(size) - 1.96
a5
effect_size <- 1
sd <- 1.5
size <- 30
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
b <-sqrt(size)
b
effect_size <- 1/1.5
sd <- 1.5
size <- 30
b <-sqrt(size)
b
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
effect_size <- 1
sd <- 1.5
size <- 30
b <-sqrt(size)
b
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
effect_size <- 1
sd <- 3/2
size <- 30
b <-sqrt(size)
b
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
effect_size <- 1/1.5
sd <- 3/2
size <- 30
b <-sqrt(size)
b
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
effect_size <- 0.5
sd <- 3/2
size <- 30
b <-sqrt(size)
b
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
effect_size <- 1
sd <- 3/2
size <- 30
b <-sqrt(size)
b
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
size <- 30
b <-sqrt(size)
b
effect_size <- 1
sd <- 1.5
size <- 30
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
effect_size <- 2
sd <- 1.5
size <- 30
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
effect_size <- 0.5
sd <- 1.5
size <- 30
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
effect_size <- 1.5
sd <- 1.5
size <- 30
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
effect_size <- 0.5
sd <- 1.5
size <- 30
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
effect_size <- 1.5
sd <- 1.5
size <- 30
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
effect_size <- 1
sd <- 1.5
size <- 30
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
effect_size <- 2
sd <- 1.5
size <- 30
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
effect_size <- 0.5
sd <- 1.5
size <- 30
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
effect_size <- 1
sd <- 1.5
size <- 30
a5 <- effect_size/(sd/sqrt(size)) - 1.96
a5
dd <- pnorm(a5)
dd
exp(-0.99296 + 0.13997)
exp(0.9131033)
exp(0.7870)
data$age.group <- as.factor(data$age.group)
data <- read.csv("/Users/kaiyangqian/Documents/Courses/Biostatistic Method II/Rcode/HW6/skincancer-3.csv")
data$Dallas <- ifelse(data$city == "Dallas", 1, 0)
model <- glm(cases ~ Dallas + offset(log(py1000)), family = poisson, data = data)
summary(model)
confint(model)
library(tidyverse)
tidy_output <- broom::tidy(model, exponentiate = TRUE, conf.int = TRUE, conf.level = 0.95)
print(tidy_output)
data$age.group <- as.factor(data$age.group)
data$age.group <- as.factor(data$age.group)
model_age_adjusted <- glm(cases ~ Dallas + age.group + offset(log(py1000)),
family = poisson, data = data)
summary(model_age_adjusted)
tidy_model_age_adjusted <- broom::tidy(model_age_adjusted, exponentiate = TRUE, conf.int = TRUE)
print(tidy_model_age_adjusted)
#2a
data$age.group <- as.factor(data$age.group)
model_age_adjusted <- glm(cases ~ Dallas + age.group + offset(log(py1000)),
family = poisson, data = data)
summary(model_age_adjusted)
tidy_model_age_adjusted <- broom::tidy(model_age_adjusted, exponentiate = TRUE, conf.int = TRUE)
print(tidy_model_age_adjusted)
print(tidy_output)
# Set working path
getwd()
setwd("/Users/kaiyangqian/Documents/Courses/Biostatistic Method II/Rcode/HW7")
#write.csv(data, "exercise_therapy.csv", row.names = FALSE)
library(foreign)
data <- read.dta("/Users/kaiyangqian/Documents/Courses/Biostatistic Method II/Rcode/HW7/exercise_therapy.dta")
#1a
# Spaghetti plot for Treatment 1
ggplot(data[data$trt == 1, ], aes(x = time, y = y, group = id, color = as.factor(id))) +
geom_line() +
geom_point() +
labs(title = "Treatment 1: Increased Repetitions", x = "Time (days)", y = "Strength") +
theme_minimal() +
scale_color_viridis_d(name = "Subject ID")
data <- read.dta("/Users/kaiyangqian/Documents/Courses/Biostatistic Method II/Rcode/HW7/exercise_therapy.dta")
model <- lmer(y ~ time * trt + (1 | id), data = data)
library(lme4)
if(!require(lme4)) install.packages("lme4")
library(lme4)
model <- lmer(y ~ time * trt + (1 | id), data = data)
summary(model)
# Fit the model with a random slope for time
model_random_slope <- lmer(y ~ time + trt + (time | id), data = data)
# Display the summary of the model
summary(model_random_slope)
model2 <- lmer(y ~ time + trt + (time | id), data = data)
summary(model2)
library(lmerTest)
if(!require(lmerTest)) install.packages("lmerTest")
library(lmerTest)
model2 <- lmer(y ~ time + trt + (time | id), data = data)
summary(model2)
